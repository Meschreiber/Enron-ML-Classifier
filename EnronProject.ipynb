{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "from time import time\n",
    "import sys\n",
    "import pickle\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "from sklearn.metrics import accuracy_score\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "#from feature_format import featureFormat, targetFeatureSplit\n",
    "#from tester import dump_classifier_and_data\n",
    "\n",
    "### Task 1: Select what features you'll use.\n",
    "### features_list is a list of strings, each of which is a feature name.\n",
    "### The first feature must be \"poi\".\n",
    "features_list = ['poi','salary', 'to_messages', 'deferral_payments', 'total_payments', 'exercised_stock_options', 'bonus', 'restricted_stock', 'shared_receipt_with_poi', 'restricted_stock_deferred', 'total_stock_value', 'expenses', 'loan_advances', 'from_messages', 'other', 'from_this_person_to_poi', 'poi', 'director_fees', 'deferred_income', 'long_term_incentive', 'from_poi_to_this_person'] # You will need to use more features\n",
    "\n",
    "### Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def featureFormat( dictionary, features, remove_NaN=True, remove_all_zeroes=True, remove_any_zeroes=False, sort_keys = False):\n",
    "    \"\"\" convert dictionary to numpy array of features\n",
    "        remove_NaN = True will convert \"NaN\" string to 0.0\n",
    "        remove_all_zeroes = True will omit any data points for which\n",
    "            all the features you seek are 0.0\n",
    "        remove_any_zeroes = True will omit any data points for which\n",
    "            any of the features you seek are 0.0\n",
    "        sort_keys = True sorts keys by alphabetical order. Setting the value as\n",
    "            a string opens the corresponding pickle file with a preset key\n",
    "            order (this is used for Python 3 compatibility, and sort_keys\n",
    "            should be left as False for the course mini-projects).\n",
    "        NOTE: first feature is assumed to be 'poi' and is not checked for\n",
    "            removal for zero or missing values.\n",
    "    \"\"\"\n",
    "\n",
    "    return_list = []\n",
    "\n",
    "    # Key order - first branch is for Python 3 compatibility on mini-projects,\n",
    "    # second branch is for compatibility on final project.\n",
    "    if isinstance(sort_keys, str):\n",
    "        import pickle\n",
    "        keys = pickle.load(open(sort_keys, \"rb\"))\n",
    "    elif sort_keys:\n",
    "        keys = sorted(dictionary.keys())\n",
    "    else:\n",
    "        keys = dictionary.keys()\n",
    "\n",
    "    for key in keys:\n",
    "        tmp_list = []\n",
    "        for feature in features:\n",
    "            try:\n",
    "                dictionary[key][feature]\n",
    "            except KeyError:\n",
    "                print \"error: key \", feature, \" not present\"\n",
    "                return\n",
    "            value = dictionary[key][feature]\n",
    "            if value==\"NaN\" and remove_NaN:\n",
    "                value = 0\n",
    "            tmp_list.append( float(value) )\n",
    "\n",
    "        # Logic for deciding whether or not to add the data point.\n",
    "        append = True\n",
    "        # exclude 'poi' class as criteria.\n",
    "        if features[0] == 'poi':\n",
    "            test_list = tmp_list[1:]\n",
    "        else:\n",
    "            test_list = tmp_list\n",
    "        ### if all features are zero and you want to remove\n",
    "        ### data points that are all zero, do that here\n",
    "        if remove_all_zeroes:\n",
    "            append = False\n",
    "            for item in test_list:\n",
    "                if item != 0 and item != \"NaN\":\n",
    "                    append = True\n",
    "                    break\n",
    "        ### if any features for a given data point are zero\n",
    "        ### and you want to remove data points with any zeroes,\n",
    "        ### handle that here\n",
    "        if remove_any_zeroes:\n",
    "            if 0 in test_list or \"NaN\" in test_list:\n",
    "                append = False\n",
    "        ### Append the data point if flagged for addition.\n",
    "        if append:\n",
    "            return_list.append( np.array(tmp_list) )\n",
    "\n",
    "    return np.array(return_list)\n",
    "\n",
    "def targetFeatureSplit( data ):\n",
    "    \"\"\" \n",
    "        given a numpy array like the one returned from\n",
    "        featureFormat, separate out the first feature\n",
    "        and put it into its own list (this should be the \n",
    "        quantity you want to predict)\n",
    "\n",
    "        return targets and features as separate lists\n",
    "\n",
    "        (sklearn can generally handle both lists and numpy arrays as \n",
    "        input formats when training/predicting)\n",
    "    \"\"\"\n",
    "\n",
    "    target = []\n",
    "    features = []\n",
    "    for item in data:\n",
    "        target.append( item[0] )\n",
    "        features.append( item[1:] )\n",
    "\n",
    "    return target, features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of  people: 146\n",
      "Number of features: 21\n",
      "Features: ['salary', 'to_messages', 'deferral_payments', 'total_payments', 'exercised_stock_options', 'bonus', 'restricted_stock', 'shared_receipt_with_poi', 'restricted_stock_deferred', 'total_stock_value', 'expenses', 'loan_advances', 'from_messages', 'other', 'from_this_person_to_poi', 'poi', 'director_fees', 'deferred_income', 'long_term_incentive', 'email_address', 'from_poi_to_this_person']\n",
      "\n",
      "Number of POI in poi_names.txt: 35\n",
      "Number of POI in dataset: 18\n",
      "\n",
      "\n",
      "Number of NaNs:\n",
      "{   'bonus': 64,\n",
      "    'deferral_payments': 107,\n",
      "    'deferred_income': 97,\n",
      "    'director_fees': 129,\n",
      "    'email_address': 35,\n",
      "    'exercised_stock_options': 44,\n",
      "    'expenses': 51,\n",
      "    'from_messages': 60,\n",
      "    'from_poi_to_this_person': 60,\n",
      "    'from_this_person_to_poi': 60,\n",
      "    'loan_advances': 142,\n",
      "    'long_term_incentive': 80,\n",
      "    'other': 53,\n",
      "    'poi': 0,\n",
      "    'restricted_stock': 36,\n",
      "    'restricted_stock_deferred': 128,\n",
      "    'salary': 51,\n",
      "    'shared_receipt_with_poi': 60,\n",
      "    'to_messages': 60,\n",
      "    'total_payments': 21,\n",
      "    'total_stock_value': 20}\n",
      "\n",
      "Number of Negative Values\n",
      "{   'bonus': 0,\n",
      "    'deferral_payments': 1,\n",
      "    'deferred_income': 49,\n",
      "    'director_fees': 0,\n",
      "    'email_address': 0,\n",
      "    'exercised_stock_options': 0,\n",
      "    'expenses': 0,\n",
      "    'from_messages': 0,\n",
      "    'from_poi_to_this_person': 0,\n",
      "    'from_this_person_to_poi': 0,\n",
      "    'loan_advances': 0,\n",
      "    'long_term_incentive': 0,\n",
      "    'other': 0,\n",
      "    'poi': 0,\n",
      "    'restricted_stock': 1,\n",
      "    'restricted_stock_deferred': 16,\n",
      "    'salary': 0,\n",
      "    'shared_receipt_with_poi': 0,\n",
      "    'to_messages': 0,\n",
      "    'total_payments': 0,\n",
      "    'total_stock_value': 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Explore features of data\n",
    "print \"Number of  people: %d\" % (len(data_dict))\n",
    "print \"Number of features: %d\" % (len(data_dict['METTS MARK']))\n",
    "print \"Features: %s\" % data_dict['METTS MARK'].keys()\n",
    "print\n",
    "poi_names = open(\"../final_project/poi_names.txt\").read().split('\\n')\n",
    "poi_y = [name for name in poi_names if \"(y)\" in name]\n",
    "poi_n = [name for name in poi_names if \"(n)\" in name]\n",
    "print \"Number of POI in poi_names.txt: %d\" % len(poi_y + poi_n)\n",
    "\n",
    "poi_count = 0\n",
    "for person in data_dict:\n",
    "\tif data_dict[person][\"poi\"]==1:\n",
    "\t\tpoi_count +=1 \n",
    "print \"Number of POI in dataset: %d\" % (poi_count)\n",
    "print\n",
    "print\n",
    "\n",
    "keys_w_nans = dict((key, 0) for key, value in data_dict['METTS MARK'].iteritems())\n",
    "keys_w_negs = dict((key, 0) for key, value in data_dict['METTS MARK'].iteritems())\n",
    "\n",
    "for person in data_dict:\n",
    "    for key, value in data_dict[person].iteritems():\n",
    "        if value == \"NaN\":\n",
    "            keys_w_nans[key] += 1\n",
    "        elif value < 0:\n",
    "            keys_w_negs[key] += 1\n",
    "\n",
    "print \"Number of NaNs:\"          \n",
    "pp.pprint(keys_w_nans)\n",
    "\n",
    "print\n",
    "print \"Number of Negative Values\"\n",
    "pp.pprint(keys_w_negs) \n",
    "print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bonus': 'NaN',\n",
       " 'deferral_payments': 'NaN',\n",
       " 'deferred_income': 'NaN',\n",
       " 'director_fees': 'NaN',\n",
       " 'email_address': 'NaN',\n",
       " 'exercised_stock_options': 'NaN',\n",
       " 'expenses': 'NaN',\n",
       " 'from_messages': 'NaN',\n",
       " 'from_poi_to_this_person': 'NaN',\n",
       " 'from_this_person_to_poi': 'NaN',\n",
       " 'loan_advances': 'NaN',\n",
       " 'long_term_incentive': 'NaN',\n",
       " 'other': 362096,\n",
       " 'poi': False,\n",
       " 'restricted_stock': 'NaN',\n",
       " 'restricted_stock_deferred': 'NaN',\n",
       " 'salary': 'NaN',\n",
       " 'shared_receipt_with_poi': 'NaN',\n",
       " 'to_messages': 'NaN',\n",
       " 'total_payments': 362096,\n",
       " 'total_stock_value': 'NaN'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove these values from the dictionary\n",
    "data_dict.pop('TOTAL')\n",
    "data_dict.pop('THE TRAVEL AGENCY IN THE PARK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Task 3: Create new feature(s)\n",
    "### Store to my_dataset for easy export below.\n",
    "my_dataset = data_dict\n",
    "\n",
    "### Extract features and labels from dataset for local testing\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = \\\n",
    "    train_test_split(features, labels, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "print len(features_train)\n",
    "print len(features_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifier:\n",
      "training time: 0.004 s\n",
      "prediction time: 0.0 s\n",
      "accuracy: 0 \n",
      "\n",
      "Support Vector Machine\n",
      "training time: 0.004 s\n",
      "prediction time: 0.0 s\n",
      "accuracy: 0 \n",
      "\n",
      "Decision Tree\n",
      "training time: 0.0 s\n",
      "prediction time: 0.0 s\n",
      "accuracy: 1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Task 4: Try a varity of classifiers\n",
    "### Please name your classifier clf for easy export below.\n",
    "### Note that if you want to do PCA or other multi-stage operations,\n",
    "### you'll need to use Pipelines. For more info:\n",
    "### http://scikit-learn.org/stable/modules/pipeline.html\n",
    "\n",
    "# Example starting point. Try investigating other evaluation techniques!\n",
    "\n",
    "# Provided to give you a starting point. Try a variety of classifiers.\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nbclf = GaussianNB()\n",
    "print \"Naive Bayes Classifier:\"\n",
    "t0 = time()\n",
    "nbclf.fit(features_train, labels_train)\n",
    "print \"training time:\", round(time()-t0, 3), \"s\"\n",
    "t0 = time()\n",
    "nbpred = nbclf.predict(features_test)\n",
    "print \"prediction time:\", round(time()-t0, 3), \"s\"\n",
    "nb_acc = accuracy_score(labels_test, nbpred)\n",
    "print \"accuracy: %d \" % nb_acc\n",
    "print\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "svm_clf = SVC(kernel=\"rbf\", C = 10000)\n",
    "print \"Support Vector Machine\"\n",
    "t0 = time()\n",
    "svm_clf.fit(features_train, labels_train)\n",
    "print \"training time:\", round(time()-t0, 3), \"s\"\n",
    "t0 = time()\n",
    "svm_pred = svm_clf.predict(features_test)\n",
    "print \"prediction time:\", round(time()-t0, 3), \"s\"\n",
    "svm_acc = accuracy_score(labels_test, svm_pred)\n",
    "print \"accuracy: %d \" % svm_acc\n",
    "print\n",
    "\n",
    "from sklearn import tree\n",
    "print \"Decision Tree\"\n",
    "split = tree.DecisionTreeClassifier(min_samples_split = 2)\n",
    "t0 = time()\n",
    "split.fit(features_train, labels_train)\n",
    "print \"training time:\", round(time()-t0, 3), \"s\"\n",
    "t0 = time()\n",
    "split_pred = split.predict(features_test)\n",
    "print \"prediction time:\", round(time()-t0, 3), \"s\"\n",
    "acc_split = accuracy_score(labels_test, split_pred)\n",
    "print \"accuracy: %d \" % acc_split\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poi\n"
     ]
    }
   ],
   "source": [
    "### Feature selection attempts\n",
    "\n",
    "#Create a numerical dataframe\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame.from_dict(data_dict)\n",
    "df = df.transpose()\n",
    "df = df.drop('email_address', 1)\n",
    "num_df = df.replace(\"NaN\", 0)\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "sel_8 = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "reduced_8 = sel_8.fit_transform(num_df)\n",
    "indices_8 = sel_8.get_support()\n",
    "\n",
    "for i in range(0, len(indices_8)):\n",
    "    if indices_8[i] == False:\n",
    "        print list(num_df.columns.values)[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh, this is rich.  After all that work (it was short code, but my basic programming skills made this take a while), the only feature with low variance is poi, which we would remove anyway.  Let's see what other columns might have relatively low variance when we change the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['from_messages', 'from_poi_to_this_person', 'from_this_person_to_poi', 'poi', 'shared_receipt_with_poi', 'to_messages']\n"
     ]
    }
   ],
   "source": [
    "def usevariance_t(thresh, df):\n",
    "    sel = VarianceThreshold(threshold=thresh)\n",
    "    reduced = sel.fit_transform(df)\n",
    "    indices = sel.get_support()\n",
    "    features = []\n",
    "    for i in range(0, len(indices)):\n",
    "        if indices[i] == False:\n",
    "            features.append(list(num_df.columns.values)[i])\n",
    "    return features\n",
    "\n",
    "print usevariance_t(10000000, num_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It makes sense that the other columns with relatively low variance are those dealing with e-mails.  That makes sense because those numbers IN GENERAL will be lower than salaries and thus variance will be lower. More and more it seems to me that the whole variance threshold thing will only really work with normalized features in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loan_advances', 'restricted_stock_deferred', 'total_payments']\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "df_scaled = min_max_scaler.fit_transform(num_df)\n",
    "df_normalized = pd.DataFrame(df_scaled)\n",
    "\n",
    "print usevariance_t(.01, df_normalized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so this might be more meaningful.  It looks like there is relatively low variance (< 0.01) within these categories.  Not sure if that means I should eliminate them yet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poi_labels = num_df['poi']\n",
    "num_df = num_df.drop('poi', 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "non_neg_df = num_df.where(num_df > 0, -num_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def iqr_outliers(df, column):\n",
    "    nan_count = 0\n",
    "    for value in column:\n",
    "        if value == 'NaN':\n",
    "            nan_count += 1\n",
    "    cleaned_column = [x for x in column if str(x) != \"NaN\"]\n",
    "    iqr = np.subtract(*np.percentile(cleaned_column, [75, 25]))\n",
    "    upper =  np.percentile(cleaned_column, 75) + 1.5 * iqr\n",
    "    lower =  np.percentile(cleaned_column, 25) - 1.5 * iqr\n",
    "    outliers = []\n",
    "    lows = 0\n",
    "    highs = 0\n",
    "    non_outliers= 0\n",
    "    for value in cleaned_column:\n",
    "        if value < lower:\n",
    "            lows += 1\n",
    "            outliers.append(value)\n",
    "        elif value > upper:\n",
    "            highs += 1\n",
    "            outliers.append(value)\n",
    "        else:\n",
    "            non_outliers += 1\n",
    "                \n",
    "    \n",
    "    return ({\"Low_outliers\": lows, \n",
    "             \"High_outliers\": highs, \n",
    "             \"NaNs\": nan_count,\n",
    "            \"Non_outliers\": non_outliers\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outlier_count = dict((name, {}) for name in df.columns)\n",
    "\n",
    "for key, value in outlier_count.iteritems():\n",
    "    value = iqr_outliers(df, df[key])\n",
    "    outlier_count[key] = value\n",
    "\n",
    "outlier_df = pd.DataFrame.from_dict(outlier_count)\n",
    "outlier_df = outlier_df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High_outliers</th>\n",
       "      <th>Low_outliers</th>\n",
       "      <th>NaNs</th>\n",
       "      <th>Non_outliers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bonus</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deferral_payments</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deferred_income</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>96</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>director_fees</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expenses</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_messages</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_advances</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_term_incentive</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poi</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restricted_stock</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>127</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to_messages</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_payments</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_stock_value</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           High_outliers  Low_outliers  NaNs  Non_outliers\n",
       "bonus                                 10             0    63            71\n",
       "deferral_payments                      6             0   106            32\n",
       "deferred_income                        0             5    96            43\n",
       "director_fees                          0             4   128            12\n",
       "exercised_stock_options               11             0    43            90\n",
       "expenses                               3             0    50            91\n",
       "from_messages                         17             0    58            69\n",
       "from_poi_to_this_person               11             0    58            75\n",
       "from_this_person_to_poi               13             0    58            73\n",
       "loan_advances                          0             0   141             3\n",
       "long_term_incentive                    7             0    79            58\n",
       "other                                 11             0    53            80\n",
       "poi                                   18             0     0           126\n",
       "restricted_stock                      13             1    35            95\n",
       "restricted_stock_deferred              1             1   127            15\n",
       "salary                                 6             3    50            85\n",
       "shared_receipt_with_poi                2             0    58            84\n",
       "to_messages                            7             0    58            79\n",
       "total_payments                        10             0    21           113\n",
       "total_stock_value                     21             0    19           104"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_support() takes at most 2 arguments (3 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-cabb0f7d8b0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnon_neg_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpoi_labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mreduced_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSelectKBest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchi2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mSelectKBest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchi2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_support\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: get_support() takes at most 2 arguments (3 given)"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "X, y = non_neg_df, poi_labels\n",
    "reduced_dim = SelectKBest(chi2, k=10).fit_transform(X, y)\n",
    "SelectKBest(chi2, k=10).get_support(X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
